\section{Introduction}

Sum-Product Networks (SPNs) was proposed as tractable deep model for probabilistic inference \cite{poon2011sum}.
In an SPN, the leaves are indicators variables for finite states of random variables and the remaining nodes are either sum or product nodes. 
The salient features of SPNs include linear inference in the size of the network and the open of discussion for semantics in deep architectures.
Applications of SPNs can be seen in image completion \cite{poon2011sum,dennis2012learning,peharz2013greedy}, computer vision \cite{amer2012sum}, classification \cite{gens2012discriminative}, speech and language modeling \cite{peharz2014modeling,cheng2014language,zohrer2015representation}.
Related models to SPNs are arithmetic circuits \cite{darwiche2003differential} and AND/OR graphs \cite{dechter2007and}
SPNs can be seen as general cases of hierarchical mixture models \cite{zhang2004hierarchical} and thin junction trees \cite{chechetka2008efficient}.


A \emph{Bayesian Network} (BN) is a factorized representation of a joint probability distribution \cite{pear88,koll09,codd70,cowell2006probabilistic,kjaerulffMadsen13}. 
As such, it can be used as an efficient knowledge representation tool for managing uncertainty in a problem domain. 
%Unfortunately, both exact and approximate inference in Bayesian networks are NP-hard \cite{coop90} and \cite{dagu93}. 
\cite{poon2011sum} has shown that SPNs and BNs are equally expressive in the sense that they can represent any disjoint distribution over discrete (or continuos) variables.
\cite{zhao2015relationship} proposed a method for converting SPNs to BNs by adopting algebraic decision diagrams (ADDs) \cite{bahar1997algebric} for representing conditional probability distribution ate each node in a BN.
The generated BN has a bipartite structure, where an latent variable is a parent of a model random variable if it is contained in the scope of the corresponding node.
The model random variables and latent variables are unconnected among each other, respectively.
\cite{peharz2015theoretical} provides a different method for generating a BN by the interpreting an augmented SPN as a hierarchical latent variable model.
The generated BN has more dependencies encoded in the graph than the other method since there are no restrictions of connectedness among latent variables or model random variables.  
Although there are some similarities between both methods, a BN generated by \cite{peharz2015theoretical} from an augmented SPN can not be obtained by \cite{zhao2015relationship} method.
That is, the conversion from augmented SPNs to BNs is not clear.


In this paper, we show that every augmented SPN can be converted into a BN.
We show that this conversion can be made in linear time and space complexity in the size of the SPN.
% [TO CHECK].
The generated BN encodes more dependencies that the method proposed by \cite{zhao2015relationship}
Our method does not require constrains on the augmented SPN.
Also, the generated BN is not restricted to a bipartite structure, hence it has a closer representation over the random variables dependencies.
Our method includes handling the identification of the nodes added to a SPN in its augmentation without creating disturbances in the BN.
When indicator variables of latent variables are introduced, they can make the SPN \emph{not valid} \cite{peharz2015theoretical}.
Rather then augmenting the SPN, we propose a different approach for this problem by simply modifying the scope of sum nodes in the SPN
This avoids the SPN growing quadratically in the size of the network by the augmentation.
We argument that our method improves the current method for converting SPN into BNs by latent variables interpretation introduction.
%Although the augmentation of an SPN is mainly a theoretical tool in \cite{peharz2015theoretical}, 


This paper is organized as follows. 
The Section \ref{sec:back} contains preliminaries, presents the notation, and describes SPNs and the two methods for obtaning a BN from SPNs
In Section \ref{sec:new} introduces a conversion algorithm for augmented SPN into BNs and a different approach for solving the mentioned problem of not valid SPN by altering the scope of some sum nodes in the SPN.
Section \ref{sec:analysis} discusses the contributions of the paper, while the Section \ref{sec:conclusion} concludes the paper.

