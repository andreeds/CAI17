\section{Introduction}

Sum-Product Networks (SPNs) was proposed as tractable deep model for probabilistic inference \cite{poon2011sum}.
In an SPN, the leaves are indicators variables for finite states of random variables and the remaining nodes are either sum or product nodes. 
The salient features of SPNs include linear inference in the size of the network and a beginning discussion of semantics in deep architectures.
Applications of SPNs can be seen in image completion \cite{poon2011sum,dennis2012learning,peharz2013greedy}, computer vision \cite{amer2012sum}, classification \cite{gens2012discriminative}, speech and language modeling \cite{peharz2014modeling,cheng2014language,zohrer2015representation}.
Related models to SPNs are arithmetic circuits \cite{darwiche2003differential} and AND/OR graphs \cite{dechter2007and}
SPNs can be seen as general cases of hierarchical mixture models \cite{zhang2004hierarchical} and thin junction trees \cite{chechetka2008efficient}.


SPNs to BNs

New Work

Remeinder

